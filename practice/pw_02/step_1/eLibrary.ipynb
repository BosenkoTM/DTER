{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SIQ6eqT4HuV"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# –ë–õ–û–ö 1: –ò–ú–ü–û–†–¢ –ë–ò–ë–õ–ò–û–¢–ï–ö –ò –û–ë–™–Ø–í–õ–ï–ù–ò–ï –§–£–ù–ö–¶–ò–ô\n",
        "# ==============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "from IPython.display import display\n",
        "\n",
        "def get_industry(title, journal):\n",
        "    \"\"\"\n",
        "    –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç —Å—Ç–∞—Ç—å—é –ø–æ –æ–¥–Ω–æ–π –∏–∑ —Ç—Ä–µ—Ö –æ—Ç—Ä–∞—Å–ª–µ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤\n",
        "    –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏ –∏ –∂—É—Ä–Ω–∞–ª–µ.\n",
        "    \"\"\"\n",
        "    title_journal_lower = (str(title) + ' ' + str(journal)).lower()\n",
        "\n",
        "    it_keywords = [\n",
        "        'computer', 'software', ' ml ', 'machine learning', 'artificial intelligence',\n",
        "        'gnn', 'recommender', 'supercomputing', 'kv stores', 'informatics', 'data',\n",
        "        'algorithm', 'internet', 'programming', 'heuristics', 'ieee',\n",
        "        'vision and applications', 'applied intelligence', 'online learning',\n",
        "        'information theory', 'robot-assisted', 'robotic'\n",
        "    ]\n",
        "\n",
        "    econ_keywords = [\n",
        "        'economic', 'finance', 'trade', 'poverty', 'development', 'policy',\n",
        "        'management', 'market', 'investment', 'sdgs', 'tourism', 'transport',\n",
        "        'financial', 'reimbursement', 'inclusion', 'business', 'corporate',\n",
        "        'wealth', 'econometric', 'socio-economic', '-economic', 'geographer',\n",
        "        'promotion management', 'lifestyle and sdgs', 'review of income',\n",
        "        'risk management', 'sustainability', 'sustainable'\n",
        "    ]\n",
        "\n",
        "    bio_keywords = [\n",
        "        'metabolomics', 'biological', 'health', 'medical', 'nursing', 'paediatric',\n",
        "        'clinical', 'vaccination', 'medicine', 'neurosurgery', 'anaesthesiologica',\n",
        "        'nutrition', 'cancer', 'palliative', 'hernia', 'care', 'urolog', 'gynecology',\n",
        "        'geriatric', 'psychology', 'adhd', 'bereavement', 'stroke', 'surgery',\n",
        "        'diabetes', 'bioscience', 'biomarkers', 'biomolecules', 'food', 'seaweed'\n",
        "    ]\n",
        "\n",
        "    if any(keyword in title_journal_lower for keyword in it_keywords):\n",
        "        return '–ò–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–∞'\n",
        "    if any(keyword in title_journal_lower for keyword in econ_keywords):\n",
        "        return '–≠–∫–æ–Ω–æ–º–∏–∫–∞'\n",
        "    if any(keyword in title_journal_lower for keyword in bio_keywords):\n",
        "        return '–ë–∏–æ–∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–∞'\n",
        "\n",
        "    return '–ü—Ä–æ—á–µ–µ'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# –ë–õ–û–ö 2: –û–°–ù–û–í–ù–ê–Ø –õ–û–ì–ò–ö–ê –°–ö–†–ò–ü–¢–ê (–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø)\n",
        "# ==============================================================================\n",
        "\n",
        "file_path = 'eLibrary.txt'\n",
        "try:\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        text_data = file.read()\n",
        "    print(f\"‚úÖ –§–∞–π–ª '{file_path}' —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ—á–∏—Ç–∞–Ω.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"‚ùå –û—à–∏–±–∫–∞: –§–∞–π–ª '{file_path}' –Ω–µ –Ω–∞–π–¥–µ–Ω!\")\n",
        "    print(\"‚û°Ô∏è –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –≤ —Ä–∞–±–æ—á—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –∏ –∑–∞–ø—É—Å—Ç–∏—Ç–µ —è—á–µ–π–∫—É —Å–Ω–æ–≤–∞.\")\n",
        "    text_data = None\n",
        "\n",
        "if text_data:\n",
        "    entries = re.split(r'\\n(?=\\d+\\n)', text_data.strip())\n",
        "    parsed_data = []\n",
        "    print(f\"–ù–∞–π–¥–µ–Ω–æ {len(entries)} –∑–∞–ø–∏—Å–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.\")\n",
        "\n",
        "    for entry in entries:\n",
        "        if not entry.strip():\n",
        "            continue\n",
        "\n",
        "        lines = [line.strip() for line in entry.strip().split('\\n') if line.strip()]\n",
        "\n",
        "        if len(lines) < 4:\n",
        "            print(f\"‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ü—Ä–æ–ø—É—Å–∫–∞–µ—Ç—Å—è –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è –∑–∞–ø–∏—Å—å: {' '.join(lines)}\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # ---  –õ–û–ì–ò–ö–ê –ü–ê–†–°–ò–ù–ì–ê ---\n",
        "\n",
        "            record_id = int(lines[0])\n",
        "\n",
        "            # –ü–æ—Å–ª–µ–¥–Ω—è—è —Å—Ç—Ä–æ–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç –∏ –∂—É—Ä–Ω–∞–ª, –∏ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è. –†–∞–∑–¥–µ–ª—è–µ–º –∏—Ö.\n",
        "            last_line = lines[-1]\n",
        "            if '\\t' in last_line:\n",
        "                journal_info_line, citations_str = last_line.rsplit('\\t', 1)\n",
        "            else:\n",
        "                journal_info_line, citations_str = last_line.rsplit(' ', 1) # –†–µ–∑–µ—Ä–≤–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç\n",
        "\n",
        "            citations_rsci = int(citations_str.strip())\n",
        "\n",
        "            # –°—Ç—Ä–æ–∫–∞ –ø–µ—Ä–µ–¥ –ø–æ—Å–ª–µ–¥–Ω–µ–π ‚Äî —ç—Ç–æ –∞–≤—Ç–æ—Ä—ã.\n",
        "            authors = lines[-2]\n",
        "\n",
        "            # –í—Å–µ, —á—Ç–æ –º–µ–∂–¥—É ID –∏ –∞–≤—Ç–æ—Ä–∞–º–∏, ‚Äî —ç—Ç–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫.\n",
        "            title = \" \".join(lines[1:-2])\n",
        "            title = re.sub(r\"^(–ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–æ—Å—Ç—É–ø–µ–Ω –Ω–∞ –≤–Ω–µ—à–Ω–µ–º —Å–∞–π—Ç–µ|–ú–æ–∂–Ω–æ –ø—Ä–∏–æ–±—Ä–µ—Å—Ç–∏ –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç —ç—Ç–æ–π –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –∑–∞ \\d+ —Ä—É–±\\.)\", \"\", title).strip()\n",
        "\n",
        "            # –ü–∞—Ä—Å–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∂—É—Ä–Ω–∞–ª–µ, –∫–∞–∫ –∏ —Ä–∞–Ω—å—à–µ\n",
        "            year_match = re.search(r'\\b(20\\d{2})\\b', journal_info_line)\n",
        "            year = int(year_match.group(1)) if year_match else None\n",
        "            journal_name = journal_info_line.split('.')[0].strip()\n",
        "\n",
        "            industry = get_industry(title, journal_name)\n",
        "\n",
        "            parsed_data.append({\n",
        "                'ID': record_id,\n",
        "                'Title': title,\n",
        "                'Authors': authors,\n",
        "                'Journal': journal_name,\n",
        "                'Year': year,\n",
        "                'Citations_RSCI': citations_rsci,\n",
        "                'Industry': industry,\n",
        "                'Source': 'eLibrary'\n",
        "            })\n",
        "        except (ValueError, IndexError) as e:\n",
        "            print(f\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø–∏—Å–∏ c ID {lines[0]}: {e}\\n   –ó–∞–ø–∏—Å—å: '{' '.join(lines[:2])}...'\\n\")\n",
        "\n",
        "    if parsed_data:\n",
        "        df = pd.DataFrame(parsed_data)\n",
        "        csv_filename = 'dataset1.csv'\n",
        "        excel_filename = 'dataset1.xlsx'\n",
        "\n",
        "        df.to_csv(csv_filename, index=False, encoding='utf-8-sig')\n",
        "        df.to_excel(excel_filename, index=False)\n",
        "\n",
        "        print(f\"\\n‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª—ã '{csv_filename}' –∏ '{excel_filename}'.\")\n",
        "        print(\"\\nüìä –ü–µ—Ä–≤—ã–µ 10 —Å—Ç—Ä–æ–∫ –∏—Ç–æ–≥–æ–≤–æ–π —Ç–∞–±–ª–∏—Ü—ã:\")\n",
        "        display(df.head(10))\n",
        "    else:\n",
        "        print(\"\\n‚ö†Ô∏è –í —Ñ–∞–π–ª–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.\")"
      ],
      "metadata": {
        "id": "Mj_gTndb4KnM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}